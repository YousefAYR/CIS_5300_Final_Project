{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_data = pd.read_csv('raw_data/2020_tweets/hashtag_donaldtrump.csv', lineterminator='\\n')\n",
    "trump_data = pd.read_csv('raw_data/2020_tweets/hashtag_joebiden.csv', lineterminator='\\n')\n",
    "biden_data['candidate'] = 'biden'\n",
    "trump_data['candidate'] = 'trump'\n",
    "data = pd.concat([trump_data, biden_data])\n",
    "\n",
    "labeled_tweets = pd.read_csv('results/labeled_tweets.csv')\n",
    "\n",
    "labeled_tweets = labeled_tweets.merge(data[['tweet_id', 'user_id']], on='tweet_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_results = pd.read_csv('results/state_election_results.csv')\n",
    "\n",
    "labeled_tweets['state_lower'] = labeled_tweets['state'].str.lower()\n",
    "election_results['state_lower'] = election_results['state'].str.lower()\n",
    "\n",
    "labeled_tweets = labeled_tweets[labeled_tweets['state_lower'].isin(election_results['state_lower'])]\n",
    "\n",
    "labeled_tweets = labeled_tweets.drop(columns=['state_lower'])\n",
    "election_results = election_results.drop(columns=['state_lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Texas             17441\n",
       "Florida           14886\n",
       "Pennsylvania       7402\n",
       "Georgia            5871\n",
       "Ohio               4775\n",
       "Nevada             4269\n",
       "Arizona            3910\n",
       "North Carolina     2800\n",
       "Michigan           2399\n",
       "Minnesota          1870\n",
       "Wisconsin          1141\n",
       "Iowa                336\n",
       "New Hampshire        56\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From https://ballotpedia.org/Presidential_battleground_states,_2020\n",
    "swing_states = ['Arizona', 'Florida', 'Georgia', 'Iowa', 'Michigan',\n",
    "                'Minnesota', 'Nevada', 'New Hampshire', 'North Carolina',\n",
    "                'Ohio', 'Pennsylvania', 'Texas', 'Wisconsin']\n",
    "labeled_tweets[labeled_tweets['state'].isin(swing_states)]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 users with multiple states\n",
      "User ID: 45721296.0, States: ['District of Columbia', 'New York']\n",
      "User ID: 49378584.0, States: ['District of Columbia', 'Florida']\n",
      "User ID: 606779465.0, States: ['California', 'Georgia']\n",
      "User ID: 734215934.0, States: ['Texas', 'New York']\n",
      "User ID: 1342861424.0, States: ['Montana', 'Texas']\n",
      "User ID: 9.639733850500916e+17, States: ['Texas', 'California']\n",
      "User ID: 1.0189151490029116e+18, States: ['New York', 'California']\n",
      "User ID: 1.02138208905959e+18, States: ['California', 'Pennsylvania']\n",
      "User ID: 1.1142462904210268e+18, States: ['District of Columbia', 'Maryland']\n",
      "User ID: 1.1451557975146742e+18, States: ['Massachusetts', 'Washington']\n",
      "User ID: 1.1562510488577352e+18, States: ['New York', 'District of Columbia']\n",
      "User ID: 1.1798153295657738e+18, States: ['Utah', 'Pennsylvania']\n",
      "User ID: 1.2438810740585062e+18, States: ['New York', 'District of Columbia']\n",
      "User ID: 1.2870247078925435e+18, States: ['Utah', 'District of Columbia']\n",
      "User ID: 1.298043766595412e+18, States: ['Texas', 'Oklahoma']\n",
      "User ID: 1.317244369921925e+18, States: ['Pennsylvania', 'Illinois']\n",
      "User ID: 1.3242667533089382e+18, States: ['Missouri', 'Tennessee']\n"
     ]
    }
   ],
   "source": [
    "multiple_states = labeled_tweets.groupby('user_id')['state'].apply(lambda x: list(x.unique()))\n",
    "users_with_multiple_states = multiple_states[multiple_states.apply(len) > 1]\n",
    "\n",
    "if not users_with_multiple_states.empty:\n",
    "    print(f'There are {len(users_with_multiple_states)} users with multiple states')\n",
    "    for user_id, states in users_with_multiple_states.items():\n",
    "        print(f\"User ID: {user_id}, States: {states}\")\n",
    "else:\n",
    "    print(\"No users have multiple states.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using population vs twitter users from https://www.pewresearch.org/internet/2019/04/24/sizing-up-twitter-users/\n",
    "\n",
    "stance_weights = pd.DataFrame({\n",
    "    'forced_stance': [-1, 1, 0],\n",
    "    'user_proportion': [0.6, 0.35, 0.05], \n",
    "    'population_proportion': [0.52, 0.43, 0.05]\n",
    "    })\n",
    "\n",
    "stance_weights['weight'] = stance_weights['population_proportion'] / stance_weights['user_proportion']\n",
    "stance_weights = stance_weights[['forced_stance', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independents alliance https://www.pewresearch.org/politics/2019/03/14/political-independents-who-they-are-what-they-think/\n",
    "proportions = np.array([17, 7, 13])\n",
    "proportions = np.divide(proportions, proportions.sum())\n",
    "\n",
    "def generate_forced_stance(avg_stance):\n",
    "    if avg_stance < 0:\n",
    "        return -1\n",
    "    elif avg_stance > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.random.choice([-1, 0, 1], p=proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_stance = labeled_tweets.groupby('user_id')['stance'].mean()\n",
    "forced_stance = labeled_tweets.groupby('user_id')['stance'].mean()\n",
    "most_frequent_state = labeled_tweets.groupby('user_id')['state'].agg(lambda x: x.mode().iloc[0])\n",
    "\n",
    "users_stances = pd.DataFrame({\n",
    "    'user_id': average_stance.index,\n",
    "    'avg_stance': average_stance.values, \n",
    "    'state': most_frequent_state.values\n",
    "})\n",
    "users_stances['forced_stance'] = users_stances['avg_stance'].apply(generate_forced_stance)\n",
    "users_stances = users_stances.merge(stance_weights, on='forced_stance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg(data, val, weight):\n",
    "    return (data[val] * data[weight]).sum() / data[weight].sum()\n",
    "\n",
    "\n",
    "weighted_avg_forced = (\n",
    "    users_stances\n",
    "    .groupby('state')\n",
    "    .apply(lambda x: weighted_avg(x, 'forced_stance', 'weight'))\n",
    "    .reset_index(name='weighted_avg_forced_stance')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>average_avg_stance</th>\n",
       "      <th>average_forced_stance</th>\n",
       "      <th>weighted_avg_forced_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>-0.137457</td>\n",
       "      <td>-0.243959</td>\n",
       "      <td>-0.091578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>-0.150601</td>\n",
       "      <td>-0.244821</td>\n",
       "      <td>-0.093163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>-0.200112</td>\n",
       "      <td>-0.326072</td>\n",
       "      <td>-0.183125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>-0.252724</td>\n",
       "      <td>-0.374046</td>\n",
       "      <td>-0.236185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>-0.150722</td>\n",
       "      <td>-0.256711</td>\n",
       "      <td>-0.108781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>-0.192139</td>\n",
       "      <td>-0.334232</td>\n",
       "      <td>-0.195819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>-0.139260</td>\n",
       "      <td>-0.191358</td>\n",
       "      <td>-0.035517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>-0.051190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>-0.163901</td>\n",
       "      <td>-0.274742</td>\n",
       "      <td>-0.126192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>-0.167936</td>\n",
       "      <td>-0.258724</td>\n",
       "      <td>-0.107471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>-0.290789</td>\n",
       "      <td>-0.142928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>-0.161628</td>\n",
       "      <td>-0.258091</td>\n",
       "      <td>-0.107652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>-0.094213</td>\n",
       "      <td>-0.134021</td>\n",
       "      <td>0.017852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  average_avg_stance  average_forced_stance  \\\n",
       "2          Arizona           -0.137457              -0.243959   \n",
       "9          Florida           -0.150601              -0.244821   \n",
       "10         Georgia           -0.200112              -0.326072   \n",
       "15            Iowa           -0.252724              -0.374046   \n",
       "22        Michigan           -0.150722              -0.256711   \n",
       "23       Minnesota           -0.192139              -0.334232   \n",
       "28          Nevada           -0.139260              -0.191358   \n",
       "29   New Hampshire           -0.051190               0.000000   \n",
       "33  North Carolina           -0.163901              -0.274742   \n",
       "35            Ohio           -0.167936              -0.258724   \n",
       "38    Pennsylvania           -0.159336              -0.290789   \n",
       "43           Texas           -0.161628              -0.258091   \n",
       "49       Wisconsin           -0.094213              -0.134021   \n",
       "\n",
       "    weighted_avg_forced_stance  \n",
       "2                    -0.091578  \n",
       "9                    -0.093163  \n",
       "10                   -0.183125  \n",
       "15                   -0.236185  \n",
       "22                   -0.108781  \n",
       "23                   -0.195819  \n",
       "28                   -0.035517  \n",
       "29                    0.160912  \n",
       "33                   -0.126192  \n",
       "35                   -0.107471  \n",
       "38                   -0.142928  \n",
       "43                   -0.107652  \n",
       "49                    0.017852  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_scores = users_stances.groupby('state')['avg_stance'].mean()\n",
    "state_scores_forced = users_stances.groupby('state')['forced_stance'].mean()\n",
    "state_scores = pd.DataFrame({\n",
    "    'state': state_scores.index,\n",
    "    'average_avg_stance': state_scores.values,\n",
    "    'average_forced_stance': state_scores_forced.values\n",
    "})\n",
    "state_scores = state_scores.merge(weighted_avg_forced, on='state')\n",
    "state_scores[state_scores['state'].isin(swing_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4150"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data = pd.read_pickle('raw_data/factoid_reddit/reddit_corpus_unbalanced_filtered.gzip', compression='gzip')\n",
    "len(reddit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = pd.read_pickle('raw_data/factoid_reddit/reddit_corpus_unbalanced_filtered.gzip', compression='gzip')\n",
    "\n",
    "columns_to_keep = [\n",
    "    'pb_factor', 'user_id'\n",
    "]\n",
    "\n",
    "reddit_data = reddit_data[columns_to_keep]\n",
    "reddit_data = pd.DataFrame({\n",
    "    \"user_id\": reddit_data[\"user_id\"],\n",
    "    \"stance\": reddit_data[\"pb_factor\"].apply(lambda x: -1 if x < -0.5 else (1 if x > 0.5 else 0))\n",
    "})\n",
    "reddit_data = reddit_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "reddit_user_stances = pd.DataFrame({\n",
    "    'user_id' : reddit_data.groupby('user_id')['stance'].mean().index,\n",
    "    'stance' : reddit_data.groupby('user_id')['stance'].mean().values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average national average stance is -0.1721383538719692\n",
      "The average national forced stance is -0.2714242003436345\n",
      "The weighted_average national forced stance is -0.2714242003436345\n",
      "The average stance from reddit data is -0.403855421686747\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average national average stance is {users_stances['avg_stance'].mean()}\")\n",
    "print(f\"The average national forced stance is {users_stances['forced_stance'].mean()}\")\n",
    "print(f\"The average stance from reddit data is {reddit_user_stances['stance'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_scores.to_csv('results/state_scores_georgetown_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
